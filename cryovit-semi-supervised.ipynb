{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-09T10:03:57.458895Z",
     "iopub.status.busy": "2025-02-09T10:03:57.458394Z",
     "iopub.status.idle": "2025-02-09T10:03:57.465197Z",
     "shell.execute_reply": "2025-02-09T10:03:57.464382Z",
     "shell.execute_reply.started": "2025-02-09T10:03:57.458865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision import transforms\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from itertools import cycle\n",
    "\n",
    "seed = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:36.658460Z",
     "iopub.status.busy": "2025-02-09T10:02:36.658093Z",
     "iopub.status.idle": "2025-02-09T10:02:36.662098Z",
     "shell.execute_reply": "2025-02-09T10:02:36.661391Z",
     "shell.execute_reply.started": "2025-02-09T10:02:36.658440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "used_ids = [\"28668\", \"28946\", \"29074\", \"29080\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:36.663311Z",
     "iopub.status.busy": "2025-02-09T10:02:36.662904Z",
     "iopub.status.idle": "2025-02-09T10:02:36.681390Z",
     "shell.execute_reply": "2025-02-09T10:02:36.680417Z",
     "shell.execute_reply.started": "2025-02-09T10:02:36.663273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total_ids = list(range(1, 129))\n",
    "labelled_indices = [i for i in range(5,121,5)]\n",
    "total_ids = [item for item in total_ids if item not in labelled_indices]\n",
    "\n",
    "random.seed(seed)\n",
    "random.shuffle(total_ids)\n",
    "\n",
    "train_size = int(0.7 * len(total_ids)) - len(labelled_indices)\n",
    "val_size = int(0.15 * len(total_ids))\n",
    "\n",
    "\n",
    "labelled_ids = []\n",
    "unlabelled_ids = []\n",
    "val_ids = []\n",
    "test_ids = []\n",
    "for ids in used_ids:\n",
    "    labelled_ids += [f\"emd_{ids}_{i}.png\" for i in range(5, 121, 5)]\n",
    "    unlabelled_ids += [f\"emd_{ids}_{i}.png\" for i in total_ids[:train_size]]\n",
    "    val_ids += [f\"emd_{ids}_{i}.png\" for i in total_ids[train_size:train_size+val_size]]\n",
    "    test_ids += [f\"emd_{ids}_{i}.png\" for i in total_ids[train_size+val_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:36.682712Z",
     "iopub.status.busy": "2025-02-09T10:02:36.682454Z",
     "iopub.status.idle": "2025-02-09T10:02:36.920230Z",
     "shell.execute_reply": "2025-02-09T10:02:36.919599Z",
     "shell.execute_reply.started": "2025-02-09T10:02:36.682692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "# Define augmentation transforms ensuring spatial transforms are applied jointly\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    # transforms.RandomAffine(\n",
    "    #     degrees=0,\n",
    "    #     translate=(0.1, 0.1),\n",
    "    #     interpolation=transforms.InterpolationMode.NEAREST\n",
    "    # ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:36.921144Z",
     "iopub.status.busy": "2025-02-09T10:02:36.920946Z",
     "iopub.status.idle": "2025-02-09T10:02:36.928937Z",
     "shell.execute_reply": "2025-02-09T10:02:36.928051Z",
     "shell.execute_reply.started": "2025-02-09T10:02:36.921128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, image_filenames, mask_filenames, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_filenames = image_filenames\n",
    "        self.mask_filenames = mask_filenames\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "        image_tensor = torch.tensor(np.array(image, dtype=np.float32) / 255.0).unsqueeze(0)  # (1, H, W)\n",
    "        mask_tensor = None\n",
    "        if self.mask_dir is not None:\n",
    "            mask_path = os.path.join(self.mask_dir, \"seg_\" + self.mask_filenames[idx])\n",
    "            mask = Image.open(mask_path).convert(\"L\") \n",
    "            mask = np.array(mask, dtype=np.float32) / 255.0\n",
    "            mask = np.where(mask > 0.5, 1.0, 0.0)  # Binarize the mask\n",
    "            mask_tensor = torch.tensor(mask).unsqueeze(0)\n",
    "            if self.transform is not None:\n",
    "                image_tensor, mask_tensor = self.transform(image_tensor, mask_tensor)\n",
    "        else:\n",
    "            if self.transform is not None:\n",
    "                image_tensor = self.transform(image_tensor)\n",
    "\n",
    "        bw_image = torch.cat([image_tensor, image_tensor, image_tensor], dim=0)\n",
    "        \n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "        \n",
    "        rgb_image = (bw_image - mean) / std\n",
    "\n",
    "        rgb_image = rgb_image.unsqueeze(0)\n",
    "        rgb_image_interp = F.interpolate(rgb_image, size=(448, 448), mode='bicubic', align_corners=False)\n",
    "        rgb_image_interp = rgb_image_interp.squeeze(0)\n",
    "\n",
    "        if self.mask_dir is not None:\n",
    "            return rgb_image_interp, mask_tensor\n",
    "        else:\n",
    "            return rgb_image_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:36.930957Z",
     "iopub.status.busy": "2025-02-09T10:02:36.930757Z",
     "iopub.status.idle": "2025-02-09T10:02:36.952268Z",
     "shell.execute_reply": "2025-02-09T10:02:36.951616Z",
     "shell.execute_reply.started": "2025-02-09T10:02:36.930941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_loaders(image_dir, mask_dir, labelled_files, unlabelled_files, val_files, test_files, batch_size, aug_transform, transform=None):\n",
    "    # Create datasets using the file lists\n",
    "    train_labelled_dataset = SegmentationDataset(image_dir, mask_dir, labelled_files, labelled_files, transform=aug_transform)\n",
    "    train_unlabelled_dataset = SegmentationDataset(image_dir, None, unlabelled_files, unlabelled_files, transform=aug_transform)\n",
    "    val_dataset = SegmentationDataset(image_dir, mask_dir, val_files, val_files, transform=transform)\n",
    "    test_dataset = SegmentationDataset(image_dir, mask_dir, test_files, test_files, transform=transform)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_labelled_loader = DataLoader(train_labelled_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    train_unlabelled_loader = DataLoader(train_unlabelled_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "    return train_labelled_loader, train_unlabelled_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:36.953899Z",
     "iopub.status.busy": "2025-02-09T10:02:36.953602Z",
     "iopub.status.idle": "2025-02-09T10:02:36.972156Z",
     "shell.execute_reply": "2025-02-09T10:02:36.971172Z",
     "shell.execute_reply.started": "2025-02-09T10:02:36.953870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_labelled_loader, train_unlabelled_loader, val_loader, test_loader = get_loaders(\n",
    "    \"/kaggle/input/cryovit-data/tomogram_images\", \n",
    "    \"/kaggle/input/cryovit-data/segmentation_mask_images\",\n",
    "    labelled_ids,\n",
    "    unlabelled_ids,\n",
    "    val_ids,\n",
    "    test_ids,\n",
    "    batch_size=8,\n",
    "    aug_transform=aug_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:36.973474Z",
     "iopub.status.busy": "2025-02-09T10:02:36.973202Z",
     "iopub.status.idle": "2025-02-09T10:02:37.247398Z",
     "shell.execute_reply": "2025-02-09T10:02:37.246505Z",
     "shell.execute_reply.started": "2025-02-09T10:02:36.973454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = 64\n",
    "mask_path = f\"/kaggle/input/cryovit-data/segmentation_mask_images/seg_emd_28668_{idx}.png\"\n",
    "mask = Image.open(mask_path)\n",
    "\n",
    "img_path = f\"/kaggle/input/cryovit-data/tomogram_images/emd_28668_{idx}.png\"\n",
    "img = Image.open(img_path)\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.imshow(mask, cmap=\"jet\", alpha=0.5)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:37.248554Z",
     "iopub.status.busy": "2025-02-09T10:02:37.248215Z",
     "iopub.status.idle": "2025-02-09T10:02:37.331504Z",
     "shell.execute_reply": "2025-02-09T10:02:37.330812Z",
     "shell.execute_reply.started": "2025-02-09T10:02:37.248499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image = torch.tensor(np.array(img, dtype=np.float32) / 255.0).unsqueeze(0)  # (1, H, W)\n",
    "bw_image = torch.cat([image, image, image], dim=0)\n",
    "\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "\n",
    "rgb_image = (bw_image - mean) / std\n",
    "rgb_image = rgb_image.unsqueeze(0)\n",
    "rgb_image_interp = F.interpolate(rgb_image, size=(448, 448), mode='bicubic', align_corners=False)\n",
    "rgb_image_interp = rgb_image_interp.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:37.332503Z",
     "iopub.status.busy": "2025-02-09T10:02:37.332243Z",
     "iopub.status.idle": "2025-02-09T10:02:38.192411Z",
     "shell.execute_reply": "2025-02-09T10:02:38.190011Z",
     "shell.execute_reply.started": "2025-02-09T10:02:37.332482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "axes[0].imshow(img, cmap=\"gray\")\n",
    "axes[0].set_title('Gray Channel')\n",
    "axes[0].axis('off')  \n",
    "\n",
    "axes[1].imshow(rgb_image_interp[0], cmap=\"Reds\")\n",
    "axes[1].set_title('Red Channel')\n",
    "axes[1].axis('off')  \n",
    "\n",
    "axes[2].imshow(rgb_image_interp[1], cmap=\"Greens\")\n",
    "axes[2].set_title('Green Channel')\n",
    "axes[2].axis('off')  \n",
    "\n",
    "axes[3].imshow(rgb_image_interp[2], cmap=\"Blues\")\n",
    "axes[3].set_title('Blue Channel')\n",
    "axes[3].axis('off')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:38.193541Z",
     "iopub.status.busy": "2025-02-09T10:02:38.193200Z",
     "iopub.status.idle": "2025-02-09T10:02:38.199645Z",
     "shell.execute_reply": "2025-02-09T10:02:38.198504Z",
     "shell.execute_reply.started": "2025-02-09T10:02:38.193488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FrozenDinoV2Backbone(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(FrozenDinoV2Backbone, self).__init__()\n",
    "        self.backbone = original_model\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False \n",
    "        self.patch_embed = original_model.patch_embed\n",
    "        self.blocks = original_model.blocks\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:38.201170Z",
     "iopub.status.busy": "2025-02-09T10:02:38.200871Z",
     "iopub.status.idle": "2025-02-09T10:02:38.217326Z",
     "shell.execute_reply": "2025-02-09T10:02:38.216490Z",
     "shell.execute_reply.started": "2025-02-09T10:02:38.201142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SynthBlock(nn.Module):\n",
    "    def __init__(self, c1, c2, c3, d1, d2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(c1, c2, 3, padding=\"same\", dilation=(d1, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(c2, c2, 3, padding=\"same\", dilation=(d2, 1, 1))\n",
    "        self.trans1 = nn.ConvTranspose3d(c2, c3, (1, 2, 2), stride=(1, 2, 2))\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gelu(self.conv1(x))\n",
    "        x = self.gelu(self.conv2(x))\n",
    "        x = self.gelu(self.trans1(x))\n",
    "        return x \n",
    "\n",
    "class CryoVIT(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(CryoVIT, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1536, 1024, 1, padding=\"same\")\n",
    "        self.synth1 = SynthBlock(c1=1024, c2=192, c3=128, d1=32, d2=24)\n",
    "        self.synth2 = SynthBlock(c1=128, c2=64, c3=32, d1=16, d2=12)\n",
    "        self.synth3 = SynthBlock(c1=32, c2=32, c3=32, d1=8, d2=4)\n",
    "        self.synth4 = SynthBlock(c1=32, c2=16, c3=8, d1=2, d2=1)\n",
    "        self.conv2 = nn.Conv3d(8, 8, 3, padding=\"same\")\n",
    "        self.conv3 = nn.Conv3d(8, 1, 3, padding=\"same\")\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)  # Ensure input shape matches expectations\n",
    "        x = self.gelu(self.conv1(x))\n",
    "        x = self.synth1(x)\n",
    "        x = self.synth2(x)\n",
    "        x = self.synth3(x)\n",
    "        x = self.synth4(x)\n",
    "        x = self.gelu(self.conv2(x))\n",
    "        self.final_act = nn.Sigmoid()\n",
    "        x = self.final_act(self.conv3(x))\n",
    "        return x.squeeze()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:02:38.218614Z",
     "iopub.status.busy": "2025-02-09T10:02:38.218274Z",
     "iopub.status.idle": "2025-02-09T10:03:15.329148Z",
     "shell.execute_reply": "2025-02-09T10:03:15.328234Z",
     "shell.execute_reply.started": "2025-02-09T10:02:38.218574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dino_model = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vitg14\", verbose=True).cuda()\n",
    "dino_backbone = FrozenDinoV2Backbone(dino_model) \n",
    "del dino_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:26:12.763351Z",
     "iopub.status.busy": "2025-02-09T10:26:12.763028Z",
     "iopub.status.idle": "2025-02-09T10:26:12.851095Z",
     "shell.execute_reply": "2025-02-09T10:26:12.850382Z",
     "shell.execute_reply.started": "2025-02-09T10:26:12.763321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cryo_vit_model = CryoVIT().to(device)\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose3d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu', a=0.1)\n",
    "    if hasattr(m, 'bias') and m.bias is not None:\n",
    "        nn.init.constant_(m.bias, 0.01)  # Small nonzero bias\n",
    "\n",
    "cryo_vit_model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:26:13.167745Z",
     "iopub.status.busy": "2025-02-09T10:26:13.167422Z",
     "iopub.status.idle": "2025-02-09T10:26:13.178081Z",
     "shell.execute_reply": "2025-02-09T10:26:13.177020Z",
     "shell.execute_reply.started": "2025-02-09T10:26:13.167721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1, conf=0.0, unlabelled=False):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.conf = conf\n",
    "        self.unlabelled = unlabelled\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.unlabelled:\n",
    "            targets = torch.where(targets > 0.5, torch.ones_like(targets), torch.zeros_like(targets))\n",
    "            \n",
    "        inputs = torch.where(inputs > self.conf, inputs, torch.zeros_like(inputs))\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)  \n",
    "        return 1 - dice\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = torch.clamp(y_pred, min=-10, max=10)  # Avoid extreme values\n",
    "        weight = (1 - y_true.mean()).clamp(0.1, 0.9)   # Keep weight stable\n",
    "        return sigmoid_focal_loss(\n",
    "            y_pred,\n",
    "            y_true,\n",
    "            alpha=weight,\n",
    "            gamma=self.gamma,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, gamma=3, weight_dice=1.0, weight_focal=1.0, weight_bce=1.0, \n",
    "                 smooth=1.0, conf=0.0, unlabelled=False):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_loss = DiceLoss(smooth=smooth, conf=conf, unlabelled=unlabelled)\n",
    "        self.focal_loss = FocalLoss(gamma=gamma)\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()  # New BCE loss\n",
    "        self.weight_dice = weight_dice\n",
    "        self.weight_focal = weight_focal\n",
    "        self.weight_bce = weight_bce  # Weight for BCE\n",
    "        self.unlabelled = unlabelled\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # print(f\"Input range: {inputs.min()} to {inputs.max()}\")\n",
    "        # print(f\"Target range: {targets.min()} to {targets.max()}\")\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "\n",
    "        probs = inputs  # Compute once for DiceLoss\n",
    "        # if self.unlabelled:\n",
    "            # targets = torch.sigmoid(targets)\n",
    "        \n",
    "        dice = self.dice_loss(probs, targets)  # Use probabilities\n",
    "        focal = self.focal_loss(inputs, targets)  # Uses logits\n",
    "        bce = self.bce_loss(inputs, targets)  # Uses logits (sigmoid applied internally)\n",
    "\n",
    "        # Handle NaNs/Infs (existing code)\n",
    "        dice = torch.nan_to_num(dice, 0.0)\n",
    "        focal = torch.nan_to_num(focal, 0.0)\n",
    "        bce = torch.nan_to_num(bce, 0.0)\n",
    "\n",
    "        return (self.weight_dice * dice + \n",
    "                self.weight_focal * focal + \n",
    "                self.weight_bce * bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:39:29.683235Z",
     "iopub.status.busy": "2025-02-09T10:39:29.682935Z",
     "iopub.status.idle": "2025-02-09T10:39:29.697864Z",
     "shell.execute_reply": "2025-02-09T10:39:29.697050Z",
     "shell.execute_reply.started": "2025-02-09T10:39:29.683210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.model.eval()\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.decay = decay\n",
    "\n",
    "    def update(self, student_model):\n",
    "        with torch.no_grad():\n",
    "            for ema_param, student_param in zip(self.model.parameters(), student_model.parameters()):\n",
    "                ema_param.data = self.decay * ema_param.data + (1 - self.decay) * student_param.data\n",
    "\n",
    "def sharpen(probs, temperature=0.5):\n",
    "    probs = probs ** (1 / temperature)\n",
    "    return probs / probs.sum(dim=1, keepdim=True)\n",
    "\n",
    "def train_model(cryo_vit_model, dino_backbone, train_labelled_loader, train_unlabelled_loader, val_loader, device, epochs=70, patience=10):\n",
    "    criterion = CombinedLoss(weight_dice=1.0, weight_focal=1.0, weight_bce=1.0)\n",
    "    criterion_unlabelled = CombinedLoss(weight_dice=1.0, weight_focal=1.0, weight_bce=1.0, conf=0.4, unlabelled=True)\n",
    "    optimizer = optim.AdamW(cryo_vit_model.parameters(), lr=5e-3, weight_decay=3e-4)\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,  # Number of iterations for the first restart\n",
    "        T_mult=2,  # A factor increases T_i after a restart\n",
    "        eta_min=1e-5  # Minimum learning rate\n",
    "    )\n",
    "    \n",
    "    ema_model = EMA(cryo_vit_model)  # Initialize EMA model\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_weights = None\n",
    "    epochs_no_improve = 0\n",
    "    history = {'train': [], 'val': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch(cryo_vit_model, ema_model, dino_backbone, train_labelled_loader, train_unlabelled_loader, criterion, criterion_unlabelled, optimizer, device)\n",
    "        val_loss = validate_epoch(cryo_vit_model, ema_model, dino_backbone, val_loader, criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        history['train'].append(train_loss)\n",
    "        history['val'].append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_weights = copy.deepcopy(cryo_vit_model.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(cryo_vit_model.state_dict(), \"best_cryo_vit_model.pth\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} with val loss: {best_loss:.4f}\")\n",
    "            break\n",
    "\n",
    "    if best_weights:\n",
    "        cryo_vit_model.load_state_dict(best_weights)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_epoch(model, ema_model, dino_backbone, labelled_loader, unlabelled_loader, \n",
    "                criterion, criterion_unlabelled, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    labelled_iter = iter(labelled_loader)\n",
    "    unlabelled_iter = iter(unlabelled_loader)\n",
    "    \n",
    "    total_iterations = min(len(labelled_loader), len(unlabelled_loader) // 2)\n",
    "    for _ in tqdm(range(total_iterations), leave=False):\n",
    "        try:\n",
    "            # Process labelled data\n",
    "            labelled_data = next(labelled_iter)\n",
    "            labelled_images, labelled_masks = labelled_data\n",
    "            labelled_images = labelled_images.to(device)\n",
    "            labelled_masks = labelled_masks.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features_labelled = dino_backbone(labelled_images).reshape(-1, 32, 32, 1536).permute(3, 0, 1, 2)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs_labelled = model(features_labelled)\n",
    "            loss_labelled = criterion(outputs_labelled, labelled_masks)\n",
    "            \n",
    "            # Process unlabelled data\n",
    "            for _ in range(2):\n",
    "                unlabelled_data = next(unlabelled_iter)\n",
    "                unlabelled_images = unlabelled_data.to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    features_unlabelled = dino_backbone(unlabelled_images).reshape(-1, 32, 32, 1536).permute(3, 0, 1, 2)\n",
    "                    ema_outputs = ema_model.model(features_unlabelled)\n",
    "                    pseudo_labels = sharpen(ema_outputs.softmax(dim=1), temperature=0.5).unsqueeze(1)\n",
    "                \n",
    "                outputs_unlabelled = model(features_unlabelled)\n",
    "                loss_unlabelled = criterion_unlabelled(outputs_unlabelled, pseudo_labels)\n",
    "                loss_labelled += loss_unlabelled\n",
    "            \n",
    "            loss_labelled.backward()\n",
    "            optimizer.step()\n",
    "            ema_model.update(model)\n",
    "            \n",
    "            total_loss += loss_labelled.item()\n",
    "            \n",
    "        except StopIteration:\n",
    "            break\n",
    "    \n",
    "    return total_loss / total_iterations\n",
    "\n",
    "def validate_epoch(model, ema_model, backbone, val_loader, criterion, device):\n",
    "    ema_model.model.eval()  # Use EMA model for validation\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, leave=False):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            features = backbone(images).reshape(-1, 32, 32, 1536).permute(3, 0, 1, 2)\n",
    "            outputs = ema_model.model(features)  # Use EMA model\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:39:31.186131Z",
     "iopub.status.busy": "2025-02-09T10:39:31.185844Z",
     "iopub.status.idle": "2025-02-09T10:39:50.173725Z",
     "shell.execute_reply": "2025-02-09T10:39:50.172304Z",
     "shell.execute_reply.started": "2025-02-09T10:39:31.186109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = train_model(cryo_vit_model, dino_backbone, train_labelled_loader, train_unlabelled_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T11:01:12.073186Z",
     "iopub.status.busy": "2025-02-08T11:01:12.072892Z",
     "iopub.status.idle": "2025-02-08T11:01:12.077446Z",
     "shell.execute_reply": "2025-02-08T11:01:12.076756Z",
     "shell.execute_reply.started": "2025-02-08T11:01:12.073163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"w\") as f:\n",
    "    json.dump(history, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:05:58.820592Z",
     "iopub.status.busy": "2025-02-09T10:05:58.820231Z",
     "iopub.status.idle": "2025-02-09T10:05:59.046689Z",
     "shell.execute_reply": "2025-02-09T10:05:59.045761Z",
     "shell.execute_reply.started": "2025-02-09T10:05:58.820554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/working/data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Train Loss\", color=\"tab:blue\")\n",
    "ax1.plot(data[\"train\"], label=\"Train Loss\", color=\"tab:blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Validation Loss\", color=\"tab:red\")\n",
    "ax2.plot(data[\"val\"], label=\"Validation Loss\", color=\"tab:red\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"tab:orange\")\n",
    "\n",
    "fig.suptitle(\"Loss Curve\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:10:49.206292Z",
     "iopub.status.busy": "2025-02-09T10:10:49.205953Z",
     "iopub.status.idle": "2025-02-09T10:10:49.210273Z",
     "shell.execute_reply": "2025-02-09T10:10:49.209509Z",
     "shell.execute_reply.started": "2025-02-09T10:10:49.206262Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = CombinedLoss(weight_dice=1.0, weight_focal=0.0, weight_bce=0.0)\n",
    "# optimizer = optim.Adam(cryo_vit_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:08:06.856247Z",
     "iopub.status.busy": "2025-02-09T10:08:06.855915Z",
     "iopub.status.idle": "2025-02-09T10:08:07.420406Z",
     "shell.execute_reply": "2025-02-09T10:08:07.419614Z",
     "shell.execute_reply.started": "2025-02-09T10:08:06.856218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/kaggle/working/best_cryo_vit_model.pth\"\n",
    "cryo_vit_model.load_state_dict(torch.load(checkpoint_path, map_location=\"cuda\"))\n",
    "cryo_vit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:10:51.832708Z",
     "iopub.status.busy": "2025-02-09T10:10:51.832352Z",
     "iopub.status.idle": "2025-02-09T10:10:51.838112Z",
     "shell.execute_reply": "2025-02-09T10:10:51.837183Z",
     "shell.execute_reply.started": "2025-02-09T10:10:51.832679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_iou(mask_gt, mask_pred):\n",
    "    # Ensure masks are binary (0 or 1)\n",
    "    mask_gt = (mask_gt > 0).to(torch.uint8)\n",
    "    mask_pred = (mask_pred > 0).to(torch.uint8)\n",
    "\n",
    "    intersection = (mask_gt & mask_pred).sum().float()\n",
    "    union = (mask_gt | mask_pred).sum().float()\n",
    "\n",
    "    return intersection / union if union > 0 else torch.tensor(0.0)\n",
    "\n",
    "def calculate_mean_iou(masks_gt, masks_pred):\n",
    "    num_images = len(masks_gt)\n",
    "    total_iou = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        iou = calculate_iou(masks_gt[i], masks_pred[i])\n",
    "        total_iou += iou\n",
    "\n",
    "    return total_iou / num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:10:52.032720Z",
     "iopub.status.busy": "2025-02-09T10:10:52.032404Z",
     "iopub.status.idle": "2025-02-09T10:12:05.259946Z",
     "shell.execute_reply": "2025-02-09T10:12:05.258859Z",
     "shell.execute_reply.started": "2025-02-09T10:10:52.032696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "tot_output = []\n",
    "tot_gt = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in tqdm(test_loader, desc=\"Inference\"):\n",
    "        images, masks = images.cuda(non_blocking=True), masks.cuda(non_blocking=True)\n",
    "\n",
    "        # Extract features using the dino backbone\n",
    "        with torch.no_grad():\n",
    "            features = dino_backbone(images) \n",
    "        features = features.reshape(-1, 32, 32, 1536).permute(3, 0, 1, 2).contiguous()\n",
    "        features = features.cuda(non_blocking=True)\n",
    "\n",
    "        # Get the model's predictions\n",
    "        outputs = cryo_vit_model(features) \n",
    "        # outputs = outputs.unsqueeze(1)  \n",
    "        temp = outputs\n",
    "        \n",
    "        tot_output.append(temp)\n",
    "        tot_gt.append(masks)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, masks)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        del features, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "avg_loss = running_loss / len(test_loader)\n",
    "iou = calculate_mean_iou(tot_gt, tot_output)\n",
    "\n",
    "print(f\"Inference Loss: {avg_loss:.4f}\")\n",
    "print(f\"Dice Score: {1 - avg_loss:.4f}\")\n",
    "print(f\"IoU: {iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:12:05.261797Z",
     "iopub.status.busy": "2025-02-09T10:12:05.261514Z",
     "iopub.status.idle": "2025-02-09T10:12:06.798270Z",
     "shell.execute_reply": "2025-02-09T10:12:06.797554Z",
     "shell.execute_reply.started": "2025-02-09T10:12:05.261774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  \n",
    "])\n",
    "\n",
    "def load_images_as_tensors(test_ids, image_dir):\n",
    "    tot_input = []\n",
    "    for file_name in test_ids:\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = transform(image)\n",
    "        tot_input.append(image_tensor)\n",
    "    return tot_input\n",
    "\n",
    "tot_input = load_images_as_tensors(test_ids, \"/kaggle/input/cryovit-data/tomogram_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:15:08.223079Z",
     "iopub.status.busy": "2025-02-09T10:15:08.222786Z",
     "iopub.status.idle": "2025-02-09T10:15:08.227631Z",
     "shell.execute_reply": "2025-02-09T10:15:08.226918Z",
     "shell.execute_reply.started": "2025-02-09T10:15:08.223057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# tot_input_cat = torch.cat(tot_input, dim=0)\n",
    "\n",
    "tot_output_cat = torch.cat(tot_output, dim=0)\n",
    "# tot_output_resized = F.interpolate(tot_output_cat, size=(448, 448), mode=\"bicubic\", align_corners=False)\n",
    "# tot_output_resized = tot_output_resized / tot_output_resized.max()  # Normalization\n",
    "\n",
    "tot_gt_cat = torch.cat(tot_gt, dim=0)\n",
    "# tot_gt_resized = F.interpolate(tot_gt_cat, size=(448, 448), mode=\"bicubic\", align_corners=False)\n",
    "# tot_gt_resized = tot_gt_resized / tot_gt_resized.max()  # Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:13:26.296801Z",
     "iopub.status.busy": "2025-02-09T10:13:26.296477Z",
     "iopub.status.idle": "2025-02-09T10:13:26.301669Z",
     "shell.execute_reply": "2025-02-09T10:13:26.300988Z",
     "shell.execute_reply.started": "2025-02-09T10:13:26.296778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tot_gt_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T10:15:13.712865Z",
     "iopub.status.busy": "2025-02-09T10:15:13.712424Z",
     "iopub.status.idle": "2025-02-09T10:15:14.124976Z",
     "shell.execute_reply": "2025-02-09T10:15:14.123944Z",
     "shell.execute_reply.started": "2025-02-09T10:15:13.712828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = 3\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Input with overlayed output\n",
    "ax[0].imshow(tot_input[idx].permute(1, 2, 0).cpu())\n",
    "ax[0].imshow((tot_output_cat[idx] > 0.5).cpu(), alpha=0.5, cmap='jet')\n",
    "ax[0].set_title(\"Predicted\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "# Ground truth\n",
    "ax[1].imshow(tot_input[idx].permute(1, 2, 0).cpu())\n",
    "ax[1].imshow(tot_gt_cat[idx][0].cpu(), alpha=0.5, cmap=\"jet\")\n",
    "ax[1].set_title(\"Ground Truth\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6603456,
     "sourceId": 10662739,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6605807,
     "sourceId": 10666358,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6632135,
     "sourceId": 10701856,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
