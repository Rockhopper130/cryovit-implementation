{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-06T12:25:23.331593Z",
     "iopub.status.busy": "2025-02-06T12:25:23.331166Z",
     "iopub.status.idle": "2025-02-06T12:25:23.340882Z",
     "shell.execute_reply": "2025-02-06T12:25:23.340052Z",
     "shell.execute_reply.started": "2025-02-06T12:25:23.331556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast\n",
    "from torchvision import transforms\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:30:33.690648Z",
     "iopub.status.busy": "2025-02-06T12:30:33.690321Z",
     "iopub.status.idle": "2025-02-06T12:30:33.694700Z",
     "shell.execute_reply": "2025-02-06T12:30:33.693891Z",
     "shell.execute_reply.started": "2025-02-06T12:30:33.690621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "used_ids = [\"28668\", \"28946\", \"29074\", \"29080\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:53:42.405669Z",
     "iopub.status.busy": "2025-02-06T12:53:42.405272Z",
     "iopub.status.idle": "2025-02-06T12:53:42.412179Z",
     "shell.execute_reply": "2025-02-06T12:53:42.411247Z",
     "shell.execute_reply.started": "2025-02-06T12:53:42.405624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total_ids = list(range(1, 129))\n",
    "random.seed(seed)\n",
    "random.shuffle(total_ids)\n",
    "\n",
    "train_size = int(0.7 * len(total_ids))\n",
    "val_size = int(0.15 * len(total_ids))\n",
    "\n",
    "train_ids = []\n",
    "val_ids = []\n",
    "test_ids = []\n",
    "for ids in used_ids:\n",
    "    train_ids += [f\"emd_{ids}_{i}.png\" for i in total_ids[:train_size]]\n",
    "    val_ids += [f\"emd_{ids}_{i}.png\" for i in total_ids[train_size:train_size+val_size]]\n",
    "    test_ids += [f\"emd_{ids}_{i}.png\" for i in total_ids[train_size+val_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:50:12.946899Z",
     "iopub.status.busy": "2025-02-06T12:50:12.946541Z",
     "iopub.status.idle": "2025-02-06T12:50:12.955820Z",
     "shell.execute_reply": "2025-02-06T12:50:12.955018Z",
     "shell.execute_reply.started": "2025-02-06T12:50:12.946859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, image_filenames, mask_filenames, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_filenames = image_filenames\n",
    "        self.mask_filenames = mask_filenames\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, \"seg_\" + self.mask_filenames[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        mask = np.array(mask, dtype=np.float32) / 255.0\n",
    "        mask = np.where(mask > 0.5, 1.0, 0.0)  # Binarize the mask\n",
    "\n",
    "        image = torch.tensor(np.array(image, dtype=np.float32) / 255.0).unsqueeze(0)  # (1, H, W)\n",
    "        mask = torch.tensor(mask).unsqueeze(0)\n",
    "\n",
    "        bw_image = torch.cat([image, image, image], dim=0)\n",
    "        \n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "        \n",
    "        rgb_image = (bw_image - mean) / std\n",
    "\n",
    "        rgb_image = rgb_image.unsqueeze(0)\n",
    "        rgb_image_interp = F.interpolate(rgb_image, size=(448, 448), mode='bicubic', align_corners=False)\n",
    "        rgb_image_interp = rgb_image_interp.squeeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "        return rgb_image_interp, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:54:04.911218Z",
     "iopub.status.busy": "2025-02-06T12:54:04.910836Z",
     "iopub.status.idle": "2025-02-06T12:54:04.916866Z",
     "shell.execute_reply": "2025-02-06T12:54:04.915943Z",
     "shell.execute_reply.started": "2025-02-06T12:54:04.911175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_loaders(image_dir, mask_dir, train_files, val_files, test_files, batch_size, transform=None):\n",
    "    # Create datasets using the file lists\n",
    "    train_dataset = SegmentationDataset(image_dir, mask_dir, train_files, train_files, transform=transform)\n",
    "    val_dataset = SegmentationDataset(image_dir, mask_dir, val_files, val_files, transform=transform)\n",
    "    test_dataset = SegmentationDataset(image_dir, mask_dir, test_files, test_files, transform=transform)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:54:05.040290Z",
     "iopub.status.busy": "2025-02-06T12:54:05.040082Z",
     "iopub.status.idle": "2025-02-06T12:54:05.044050Z",
     "shell.execute_reply": "2025-02-06T12:54:05.043301Z",
     "shell.execute_reply.started": "2025-02-06T12:54:05.040273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_loaders(\n",
    "    \"/kaggle/input/cryovit-data/tomogram_images\", \n",
    "    \"/kaggle/input/cryovit-data/segmentation_mask_images\",\n",
    "    train_ids,\n",
    "    val_ids,\n",
    "    test_ids,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:11:12.063510Z",
     "iopub.status.busy": "2025-02-06T12:11:12.063225Z",
     "iopub.status.idle": "2025-02-06T12:11:12.472287Z",
     "shell.execute_reply": "2025-02-06T12:11:12.471392Z",
     "shell.execute_reply.started": "2025-02-06T12:11:12.063488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = 64\n",
    "mask_path = f\"/kaggle/input/cryovit-data/segmentation_mask_images/seg_emd_28668_{idx}.png\"\n",
    "mask = Image.open(mask_path)\n",
    "\n",
    "img_path = f\"/kaggle/input/cryovit-data/tomogram_images/emd_28668_{idx}.png\"\n",
    "img = Image.open(img_path)\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.imshow(mask, cmap=\"jet\", alpha=0.5)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:11:13.563596Z",
     "iopub.status.busy": "2025-02-06T12:11:13.563293Z",
     "iopub.status.idle": "2025-02-06T12:11:13.624355Z",
     "shell.execute_reply": "2025-02-06T12:11:13.623529Z",
     "shell.execute_reply.started": "2025-02-06T12:11:13.563573Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image = torch.tensor(np.array(img, dtype=np.float32) / 255.0).unsqueeze(0)  # (1, H, W)\n",
    "bw_image = torch.cat([image, image, image], dim=0)\n",
    "\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "\n",
    "rgb_image = (bw_image - mean) / std\n",
    "rgb_image = rgb_image.unsqueeze(0)\n",
    "rgb_image_interp = F.interpolate(rgb_image, size=(448, 448), mode='bicubic', align_corners=False)\n",
    "rgb_image_interp = rgb_image_interp.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:11:13.889748Z",
     "iopub.status.busy": "2025-02-06T12:11:13.889477Z",
     "iopub.status.idle": "2025-02-06T12:11:14.688106Z",
     "shell.execute_reply": "2025-02-06T12:11:14.685679Z",
     "shell.execute_reply.started": "2025-02-06T12:11:13.889724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "axes[0].imshow(img, cmap=\"gray\")\n",
    "axes[0].set_title('Gray Channel')\n",
    "axes[0].axis('off')  \n",
    "\n",
    "axes[1].imshow(rgb_image_interp[0], cmap=\"Reds\")\n",
    "axes[1].set_title('Red Channel')\n",
    "axes[1].axis('off')  \n",
    "\n",
    "axes[2].imshow(rgb_image_interp[1], cmap=\"Greens\")\n",
    "axes[2].set_title('Green Channel')\n",
    "axes[2].axis('off')  \n",
    "\n",
    "axes[3].imshow(rgb_image_interp[2], cmap=\"Blues\")\n",
    "axes[3].set_title('Blue Channel')\n",
    "axes[3].axis('off')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:48:25.301995Z",
     "iopub.status.busy": "2025-02-06T12:48:25.301655Z",
     "iopub.status.idle": "2025-02-06T12:48:25.306615Z",
     "shell.execute_reply": "2025-02-06T12:48:25.305948Z",
     "shell.execute_reply.started": "2025-02-06T12:48:25.301966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FrozenDinoV2Backbone(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(FrozenDinoV2Backbone, self).__init__()\n",
    "        self.backbone = original_model\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False \n",
    "        self.patch_embed = original_model.patch_embed\n",
    "        self.blocks = original_model.blocks\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:48:25.426074Z",
     "iopub.status.busy": "2025-02-06T12:48:25.425818Z",
     "iopub.status.idle": "2025-02-06T12:48:25.434496Z",
     "shell.execute_reply": "2025-02-06T12:48:25.433633Z",
     "shell.execute_reply.started": "2025-02-06T12:48:25.426052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SynthBlock(nn.Module):\n",
    "    def __init__(self, c1, c2, c3, d1, d2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(c1, c2, 3, padding=\"same\", dilation=(d1, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(c2, c2, 3, padding=\"same\", dilation=(d2, 1, 1))\n",
    "        self.trans1 = nn.ConvTranspose3d(c2, c3, (1, 2, 2), stride=(1, 2, 2))\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gelu(self.conv1(x))\n",
    "        x = self.gelu(self.conv2(x))\n",
    "        x = self.gelu(self.trans1(x))\n",
    "        return x\n",
    "\n",
    "class CryoVIT(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(CryoVIT, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1536, 1024, 1, padding=\"same\")\n",
    "        self.synth1 = SynthBlock(c1=1024, c2=192, c3=128, d1=32, d2=24)\n",
    "        self.synth2 = SynthBlock(c1=128, c2=64, c3=32, d1=16, d2=12)\n",
    "        self.synth3 = SynthBlock(c1=32, c2=32, c3=32, d1=8, d2=4)\n",
    "        self.synth4 = SynthBlock(c1=32, c2=16, c3=8, d1=2, d2=1)\n",
    "        self.conv2 = nn.Conv3d(8, 8, 3, padding=\"same\")\n",
    "        self.conv3 = nn.Conv3d(8, 1, 3, padding=\"same\")\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)  # Ensure input shape matches expectations\n",
    "        x = self.gelu(self.conv1(x))\n",
    "        x = self.synth1(x)\n",
    "        x = self.synth2(x)\n",
    "        x = self.synth3(x)\n",
    "        x = self.synth4(x)\n",
    "        x = self.gelu(self.conv2(x))\n",
    "        x = self.conv3(x)  \n",
    "        return x.squeeze()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:48:27.258577Z",
     "iopub.status.busy": "2025-02-06T12:48:27.258290Z",
     "iopub.status.idle": "2025-02-06T12:48:27.266361Z",
     "shell.execute_reply": "2025-02-06T12:48:27.265443Z",
     "shell.execute_reply.started": "2025-02-06T12:48:27.258555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)       \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)  \n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        weight = (y_true.numel() - y_true.sum()) / y_true.numel()\n",
    "        return sigmoid_focal_loss(\n",
    "            y_pred,\n",
    "            y_true,\n",
    "            alpha=weight,\n",
    "            gamma=self.gamma,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, weight_dice=1.0, weight_focal=1.0, smooth=1.0):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_loss = DiceLoss(smooth=smooth)\n",
    "        self.focal_loss = FocalLoss(gamma=gamma)\n",
    "        self.weight_dice = weight_dice\n",
    "        self.weight_focal = weight_focal\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        dice_loss_value = self.dice_loss(inputs, targets)\n",
    "        focal_loss_value = self.focal_loss(inputs, targets)\n",
    "        combined_loss = self.weight_dice * dice_loss_value + self.weight_focal * focal_loss_value\n",
    "        return combined_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:48:30.775766Z",
     "iopub.status.busy": "2025-02-06T12:48:30.775480Z",
     "iopub.status.idle": "2025-02-06T12:48:53.770293Z",
     "shell.execute_reply": "2025-02-06T12:48:53.769570Z",
     "shell.execute_reply.started": "2025-02-06T12:48:30.775744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dino_model = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vitg14\", verbose=True).cuda()\n",
    "dino_backbone = FrozenDinoV2Backbone(dino_model) \n",
    "del dino_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:48:53.771619Z",
     "iopub.status.busy": "2025-02-06T12:48:53.771313Z",
     "iopub.status.idle": "2025-02-06T12:48:54.060051Z",
     "shell.execute_reply": "2025-02-06T12:48:54.059392Z",
     "shell.execute_reply.started": "2025-02-06T12:48:53.771590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cryo_vit_model = CryoVIT().to(device)\n",
    "\n",
    "def initialize_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            init.kaiming_normal_(param, mode='fan_in', nonlinearity='relu')\n",
    "        elif 'bias' in name:\n",
    "            init.zeros_(param)\n",
    "\n",
    "# Initialize your model with He initialization\n",
    "initialize_weights(cryo_vit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:48:54.061786Z",
     "iopub.status.busy": "2025-02-06T12:48:54.061466Z",
     "iopub.status.idle": "2025-02-06T12:48:54.066096Z",
     "shell.execute_reply": "2025-02-06T12:48:54.065046Z",
     "shell.execute_reply.started": "2025-02-06T12:48:54.061739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = CombinedLoss(weight_dice=1.0, weight_focal=1.0)\n",
    "optimizer = optim.Adam(cryo_vit_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:50:18.145721Z",
     "iopub.status.busy": "2025-02-06T12:50:18.145371Z",
     "iopub.status.idle": "2025-02-06T12:50:29.951904Z",
     "shell.execute_reply": "2025-02-06T12:50:29.950463Z",
     "shell.execute_reply.started": "2025-02-06T12:50:18.145685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_loss = float('inf')\n",
    "loss_history = []\n",
    "\n",
    "patience = 3  # Stop training if no improvement for 'patience' epochs\n",
    "epochs_no_improve = 0  # Counter for early stopping\n",
    "min_delta = 1e-4  # Minimum change to qualify as an improvement\n",
    "\n",
    "epochs = 40  \n",
    "for epoch in range(epochs):\n",
    "    cryo_vit_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        images, masks = images.cuda(non_blocking=True), masks.cuda(non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            features = dino_backbone(images) \n",
    "        features = features.reshape(-1, 32, 32, 1536).permute(3, 0, 1, 2)\n",
    "        features = features.cuda(non_blocking=True)\n",
    "        outputs = cryo_vit_model(features)  \n",
    "        outputs = outputs.unsqueeze(1)  \n",
    "        loss = criterion(outputs, masks)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del features, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    cryo_vit_model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.cuda(non_blocking=True), masks.cuda(non_blocking=True)\n",
    "            features = dino_backbone(images)\n",
    "            features = features.reshape(-1, 32, 32, 1536).permute(3, 0, 1, 2)\n",
    "            features = features.cuda(non_blocking=True)\n",
    "            outputs = cryo_vit_model(features)\n",
    "            outputs = outputs.unsqueeze(1)\n",
    "            val_loss += criterion(outputs, masks).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_loss - min_delta:\n",
    "        best_loss = avg_val_loss\n",
    "        torch.save(cryo_vit_model.state_dict(), \"cryo_vit_model_best.pth\")\n",
    "        print(f\"Model saved at epoch {epoch+1} with validation loss: {avg_val_loss:.4f}\")\n",
    "        epochs_no_improve = 0  # Reset counter\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:56:29.214915Z",
     "iopub.status.busy": "2025-02-06T12:56:29.214555Z",
     "iopub.status.idle": "2025-02-06T12:56:29.456756Z",
     "shell.execute_reply": "2025-02-06T12:56:29.455924Z",
     "shell.execute_reply.started": "2025-02-06T12:56:29.214885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history, label='Training Loss', color='b', linewidth=2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.savefig('training_loss_plot.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:54:11.911538Z",
     "iopub.status.busy": "2025-02-06T12:54:11.911248Z",
     "iopub.status.idle": "2025-02-06T12:54:11.956038Z",
     "shell.execute_reply": "2025-02-06T12:54:11.955317Z",
     "shell.execute_reply.started": "2025-02-06T12:54:11.911516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/kaggle/input/cryovit-trained/cryo_vit_model_best.pth\"\n",
    "cryo_vit_model.load_state_dict(torch.load(checkpoint_path, map_location=\"cuda\"))\n",
    "cryo_vit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:54:16.192685Z",
     "iopub.status.busy": "2025-02-06T12:54:16.192381Z",
     "iopub.status.idle": "2025-02-06T12:54:51.772305Z",
     "shell.execute_reply": "2025-02-06T12:54:51.771387Z",
     "shell.execute_reply.started": "2025-02-06T12:54:16.192662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "tot_output = []\n",
    "tot_input = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in tqdm(test_loader, desc=\"Inference\"):\n",
    "        images, masks = images.cuda(non_blocking=True), masks.cuda(non_blocking=True)\n",
    "\n",
    "        # Extract features using the dino backbone\n",
    "        with torch.no_grad():\n",
    "            features = dino_backbone(images) \n",
    "        features = features.reshape(-1, 32, 32, 1536).permute(3, 0, 1, 2).contiguous()\n",
    "        features = features.cuda(non_blocking=True)\n",
    "\n",
    "        # Get the model's predictions\n",
    "        outputs = cryo_vit_model(features) \n",
    "        outputs = outputs.unsqueeze(1)  \n",
    "        temp = outputs\n",
    "        \n",
    "        tot_input.append(images)\n",
    "        tot_output.append(temp)\n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, masks)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        del features, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "avg_loss = running_loss / len(test_loader)\n",
    "print(f\"Inference Loss: {avg_loss:.4f}\")\n",
    "tot_output = torch.cat(tot_output, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:13:10.176634Z",
     "iopub.status.busy": "2025-02-06T12:13:10.176346Z",
     "iopub.status.idle": "2025-02-06T12:13:10.180205Z",
     "shell.execute_reply": "2025-02-06T12:13:10.179384Z",
     "shell.execute_reply.started": "2025-02-06T12:13:10.176609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch.save(tot_output, \"inference_output.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:54:57.794157Z",
     "iopub.status.busy": "2025-02-06T12:54:57.793838Z",
     "iopub.status.idle": "2025-02-06T12:54:57.798927Z",
     "shell.execute_reply": "2025-02-06T12:54:57.798065Z",
     "shell.execute_reply.started": "2025-02-06T12:54:57.794130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tot_input = torch.cat(tot_input, dim=0)\n",
    "tot_output_resized = F.interpolate(tot_output, size=(448, 448), mode=\"bicubic\", align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:54:59.235621Z",
     "iopub.status.busy": "2025-02-06T12:54:59.235301Z",
     "iopub.status.idle": "2025-02-06T12:54:59.240313Z",
     "shell.execute_reply": "2025-02-06T12:54:59.239435Z",
     "shell.execute_reply.started": "2025-02-06T12:54:59.235594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(tot_input.shape)\n",
    "print(tot_output_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T12:55:15.707622Z",
     "iopub.status.busy": "2025-02-06T12:55:15.707327Z",
     "iopub.status.idle": "2025-02-06T12:55:15.948369Z",
     "shell.execute_reply": "2025-02-06T12:55:15.947541Z",
     "shell.execute_reply.started": "2025-02-06T12:55:15.707600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = 4\n",
    "plt.imshow(tot_input[idx].permute(1,2,0).cpu())\n",
    "plt.imshow((tot_output_resized[idx][0] > 0.5).float().cpu(), alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6603456,
     "sourceId": 10662739,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6605807,
     "sourceId": 10666358,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
